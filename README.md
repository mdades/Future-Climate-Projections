# Future-Climate-Projections
This project, conducted as part of my Master’s degree in Applied Mathematics and Statistics (Université de Bordeaux, 2024–2025) in collaboration with the CNRS, focuses on improving the accuracy of future climate projections by applying statistical uncertainty reduction methods to data from the CMIP6 (Coupled Model Intercomparison Project Phase 6). The dataset includes global mean temperature anomalies simulated by 25 different climate models from 1850 to 2099, as well as observed anomalies from 1850 to 2021. The main goal was to estimate the projected temperature anomaly around the year 2099 and to reduce the uncertainty associated with model variability. I began by analyzing and cleaning the data, identifying the different matrices (simulated past, simulated future, observed past, and observational uncertainty), and confirming their coherence. Then, I visualized the temperature evolution over time to compare models with real observations, and I verified that the data followed a normal distribution using QQ-plots and the Shapiro–Wilk test, which allowed me to compute confidence intervals for 2099. Next, I implemented and compared several statistical approaches: (1) the multi-model mean, which takes the simple average across all models; (2) a weighted mean, which assigns higher weights to models that better match past observations and are more independent from others; (3) a linear regression, linking past anomalies (1950–2000) to future anomalies (2090–2099); and (4) a One-Step Kalman filter, which optimally combines simulated and observed information while accounting for uncertainties. Each method was evaluated based on the mean projection and the associated uncertainty (standard deviation). I also performed a Leave-One-Out Cross-Validation to test the robustness and detect possible overfitting. Finally, I extended the study to a multivariate approach, using full time series of past anomalies as predictors, and applied advanced techniques such as Ridge regression, Partial Least Squares (PLS), Random Forests, and Principal Component Analysis (PCA) for dimension reduction. The results showed that the One-Step Kalman method provided the smallest uncertainty (≈1.03°C), while Random Forest with PCA further improved predictive performance (RMSE ≈ 0.80). Overall, the analysis indicates a projected global temperature anomaly of about +5.3°C by 2099, consistent with the SSP5-8.5 high-emission scenario. This project demonstrates how statistical modeling and machine learning can help reduce uncertainties in climate projections and provide more reliable insights for climate policy and adaptation planning.
